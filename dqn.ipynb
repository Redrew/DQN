{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "version": "3.7.4-final"
    },
    "orig_nbformat": 2,
    "file_extension": ".py",
    "mimetype": "text/x-python",
    "name": "python",
    "npconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": 3,
    "kernelspec": {
      "name": "python37664bita8a520b5e33a46a98b8cb2a6fbfac073",
      "display_name": "Python 3.7.6 64-bit"
    },
    "colab": {
      "name": "dqn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4HZHW3TjbCl",
        "colab_type": "code",
        "outputId": "d56986dd-731a-4044-a9f5-4a50a35edad1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        }
      },
      "source": [
        "import sys\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "  !nvidia-smi\n",
        "\n",
        "  # mount google drive to colab\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "  # Install TensorFlow on Colab\n",
        "  try:\n",
        "    # %tensorflow_version only exists in Colab.\n",
        "    %tensorflow_version 2.x\n",
        "  except Exception:\n",
        "    pass\n",
        "\n",
        "  PATH = 'drive/My Drive/Colab Notebooks/'\n",
        "else:\n",
        "  PATH = ''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Feb  4 04:28:37 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.48.02    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvVXZLvOtBey",
        "colab_type": "code",
        "outputId": "a72c724a-aec8-463a-c4eb-bc265a8378b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.layers as layers\n",
        "import time\n",
        "import pickle\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLG9kdS1tBfb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "env = gym.make('Pong-v0')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YaPGBb5tBfr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rgb2gray(rgb):\n",
        "    return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140]).astype(np.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79nn1qcFtBf1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def crop(img, size):\n",
        "    x = (img.shape[0] - size[0]) // 2\n",
        "    y = (img.shape[1] - size[1]) // 2\n",
        "    return img[x:x+size[0], y:y+size[1]]\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsxcFkk1tBgq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def process_img(img):\n",
        "    img = rgb2gray(img)\n",
        "    img = cv2.resize(img, (84, 110))\n",
        "    img = crop(img, (84, 84))\n",
        "    return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qkhQpy4tBg2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ExpBuffer(list):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.capacity = 1e6\n",
        "\n",
        "    def append(self, x):\n",
        "        if len(self) >= self.capacity:\n",
        "            self.pop(0)\n",
        "        super().append(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8C0jGSWktBg-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def skip_frames(n):\n",
        "    exp_stack = []\n",
        "    for _ in range(n):\n",
        "        exp_stack.append(env.step(0))\n",
        "        # break if done\n",
        "        if exp_stack[-1][2]:\n",
        "            break\n",
        "    return exp_stack"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oppw7Tn6tBhG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def one_hot_mse(predicted_y, target_y):\n",
        "    one_hot = tf.one_hot(target_y[1], predicted_y.shape[-1])\n",
        "    return tf.reduce(tf.square(one_hot * predicted_y - one_hot * target_y[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0b97hjEttBhT",
        "colab_type": "text"
      },
      "source": [
        "Action space\n",
        "\n",
        "0 | 1 | 2 | 3 | 4 | 5\n",
        "--- | --- | --- | --- | --- | ---\n",
        "Nothing | Nothing | Up | Down | Up | Down"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaBsrrZItBhW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# There are only 3 unique actions in the space\n",
        "action_2_space = {0:0, 1:2, 2:3}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Zq-CxJ7tBhi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class T():\n",
        "    s = 0\n",
        "    a = 1\n",
        "    r = 2\n",
        "    s_next = 3\n",
        "    terminal = 4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQRqSU3UtBhq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class E():\n",
        "    s = 0\n",
        "    r = 1\n",
        "    done = 2\n",
        "    info = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccsYXF1UtBiF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.RMSprop()\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    layers.Conv2D(16, 8, 4, activation='relu'),\n",
        "    layers.Conv2D(32, 4, 2, activation='relu'),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dense(3)\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6Dd4OOqtBio",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def selective_mse(y_true, y_pred, actions):\n",
        "    y_true = tf.cast(y_true, tf.dtypes.float32)\n",
        "    actions = list(enumerate(actions))\n",
        "    dif = y_true - tf.gather_nd(y_pred, actions)\n",
        "    return tf.reduce_mean(tf.square(dif))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3C8YWM8rtBjE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def step(model, exp_buffer, optimizer, batch_size=32):\n",
        "    loss_value = 0\n",
        "    if (len(exp_buffer) != 0):\n",
        "        x_batch = []\n",
        "        y_batch = []\n",
        "        a_batch = []\n",
        "\n",
        "        for _ in range(batch_size):\n",
        "            i = np.random.randint(len(exp_buffer))\n",
        "            x_batch.append(exp_buffer[i][T.s])\n",
        "            a_batch.append(exp_buffer[i][T.a])\n",
        "            if exp_buffer[i][T.terminal]:\n",
        "                y_batch.append(exp_buffer[i][T.r])\n",
        "            else:\n",
        "                qmax = np.max(model(np.expand_dims(exp_buffer[i][T.s_next], 0)))\n",
        "                y_batch.append(exp_buffer[i][T.r] + qmax)\n",
        "\n",
        "        x_batch = tf.convert_to_tensor(x_batch)\n",
        "        y_batch = tf.convert_to_tensor(y_batch)\n",
        "\n",
        "        with tf.GradientTape() as t:\n",
        "            y_pred = model(x_batch)\n",
        "            loss_value = selective_mse(y_batch, y_pred, a_batch)\n",
        "        grads = t.gradient(loss_value, model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "    return loss_value"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KL8IxqEbinFw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save variables in google drive\n",
        "def save(num=1):\n",
        "  training_variables = {'e': e, 'exp_buffer': exp_buffer, 'optimizer_weights': optimizer.weights, \n",
        "                        'num_updates': num_updates}\n",
        "  with open(PATH + 'dqn-pong-model/training_variables.p', 'wb') as file:\n",
        "    pickle.dump(training_variables, file)\n",
        "  model.save_weights(PATH + 'dqn-pong-model/weights')\n",
        "  if num % 2000 == 0:\n",
        "    with open(PATH + 'dqn-pong-model/training_variables_bk.p', 'wb') as file:\n",
        "      pickle.dump(training_variables, file)\n",
        "    model.save_weights(PATH + 'dqn-pong-model/weights_bk')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiSekYlfDirX",
        "colab_type": "code",
        "outputId": "5f2ce2e6-ed25-474f-d50f-d44e8454bd6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "'''\n",
        "x_batch = []\n",
        "y_batch = []\n",
        "a_batch = []\n",
        "\n",
        "for _ in range(32):\n",
        "    i = np.random.randint(len(exp_buffer))\n",
        "    x_batch.append(exp_buffer[i][T.s])\n",
        "    a_batch.append(exp_buffer[i][T.a])\n",
        "    if exp_buffer[i][T.terminal]:\n",
        "        y_batch.append(exp_buffer[i][T.r])\n",
        "    else:\n",
        "        qmax = np.max(model(np.expand_dims(exp_buffer[i][T.s_next], 0)))\n",
        "        y_batch.append(exp_buffer[i][T.r] + qmax)\n",
        "\n",
        "start_time = time.time()\n",
        "_ = tf.convert_to_tensor(x_batch)\n",
        "_ = tf.convert_to_tensor(y_batch)\n",
        "print('batching time: {}'.format(time.time() - start_time))\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nx_batch = []\\ny_batch = []\\na_batch = []\\n\\nfor _ in range(32):\\n    i = np.random.randint(len(exp_buffer))\\n    x_batch.append(exp_buffer[i][T.s])\\n    a_batch.append(exp_buffer[i][T.a])\\n    if exp_buffer[i][T.terminal]:\\n        y_batch.append(exp_buffer[i][T.r])\\n    else:\\n        qmax = np.max(model(np.expand_dims(exp_buffer[i][T.s_next], 0)))\\n        y_batch.append(exp_buffer[i][T.r] + qmax)\\n\\nstart_time = time.time()\\n_ = tf.convert_to_tensor(x_batch)\\n_ = tf.convert_to_tensor(y_batch)\\nprint('batching time: {}'.format(time.time() - start_time))\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imcH9ioDUmjq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "load = True\n",
        "reset = False\n",
        "episodes = 60\n",
        "render = False\n",
        "\n",
        "loss_log = []\n",
        "if load:\n",
        "  # load past variables\n",
        "  model.load_weights(PATH + 'dqn-pong-model/weights')\n",
        "  with open(PATH + 'dqn-pong-model/training_variables.p', 'rb') as file:\n",
        "    training_variables = pickle.load(file)\n",
        "  e = training_variables['e']\n",
        "  exp_buffer = training_variables['exp_buffer']\n",
        "  optimizer_weights = training_variables['optimizer_weights']\n",
        "  num_updates = training_variables['num_updates']\n",
        "if reset:\n",
        "  exp_buffer = ExpBuffer()\n",
        "  e = 1\n",
        "  num_updates = 0\n",
        "\n",
        "# one epoch corresponds to 50000 updates, aim for 100 epochs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBuPp8c8L3EH",
        "colab_type": "code",
        "outputId": "43dffbfd-f3c9-485c-a04f-1b750f081224",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'Epoch: {} / 100'.format(num_updates / 50000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Epoch: 0.84 / 100'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ot4IrEistBjb",
        "colab_type": "code",
        "outputId": "8c6d4a3a-4408-4d1a-b342-96708b0598d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "# training loop\n",
        "for i_episode in range(episodes):\n",
        "    start_time = time.time()\n",
        "    for t in range(1500):\n",
        "        # track the time spent computing one step\n",
        "        if (t % 50 == 0 ):\n",
        "          print(time.time() - start_time)\n",
        "        start_time = time.time()\n",
        "\n",
        "        # skip first 3 frames\n",
        "        if t == 0:\n",
        "            observation = env.reset()\n",
        "            exp_stack = [[observation, 0, None, None]]\n",
        "            exp_stack.extend(skip_frames(2))\n",
        "        else:\n",
        "            exp_stack = skip_frames(3)\n",
        "        if exp_stack[-1][E.done]:\n",
        "            break\n",
        "\n",
        "        # agent choose action with annealing e greedy\n",
        "        if t == 0 or np.random.random() < e:\n",
        "            action = np.random.choice(list(action_2_space.keys()))\n",
        "        else:\n",
        "            q = model(np.expand_dims(exp_buffer[-1][T.s], 0))\n",
        "            action = int(np.argmax(q, axis=1))\n",
        "        e -= (1 - 0.1) / 1e6\n",
        "\n",
        "        # update weights on past experience minibatch, size=32\n",
        "        loss_log.append(step(model, exp_buffer, optimizer))\n",
        "        num_updates += 1\n",
        "\n",
        "        # stack frames into one state and add a new transition experience to experience buffer\n",
        "        exp = env.step(action_2_space[action])\n",
        "        exp_stack.append(exp)\n",
        "        img_stack = np.stack([process_img(exp[0]) for exp in exp_stack], axis=2)\n",
        "        reward = np.sum([exp[1] for exp in exp_stack])\n",
        "        if t != 0:\n",
        "            # s(t), a, r, s(t+1), terminal\n",
        "            exp_buffer.append([last_img_stack, action, reward, img_stack, False])\n",
        "        last_img_stack = img_stack\n",
        "\n",
        "        # render gameplay\n",
        "        if render:\n",
        "          plt.imshow(env.render(mode='rgb_array'))\n",
        "          display.display(plt.gcf())\n",
        "          display.clear_output(wait=True)\n",
        "\n",
        "        # checkpoint progress\n",
        "        if num_updates % 1000 == 0:\n",
        "          save(num_updates)\n",
        "\n",
        "        if exp_stack[-1][E.done]:\n",
        "            break\n",
        "            \n",
        "    # set last transition to be terminal\n",
        "    if len(exp_stack) != 0:\n",
        "        exp_buffer[-1][T.terminal] = True\n",
        "    print('Episode {} finished after {} timesteps'.format(i_episode, t))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAM4AAAD8CAYAAAA/rZtiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gjmy9tJY6t6e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "save()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzUb3hC9tBjg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = exp_buffer[np.random.randint(len(exp_buffer))][0]\n",
        "print(model(np.expand_dims(img, 0)))\n",
        "plt.imshow(img[...,1], cmap='gray')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBk9NNU0tBjm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#env.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKY3T_l8b7ng",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}